{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971241e9-536f-4703-8f54-d15e90405e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.9840 - accuracy: 0.4799 - val_loss: 0.9859 - val_accuracy: 0.4770\n",
      "Epoch 2/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8499 - accuracy: 0.5776 - val_loss: 0.9253 - val_accuracy: 0.5517\n",
      "Epoch 3/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7871 - accuracy: 0.6164 - val_loss: 0.9119 - val_accuracy: 0.5517\n",
      "Epoch 4/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7527 - accuracy: 0.6207 - val_loss: 0.9004 - val_accuracy: 0.5632\n",
      "Epoch 5/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7321 - accuracy: 0.6351 - val_loss: 0.9011 - val_accuracy: 0.5747\n",
      "Epoch 6/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7185 - accuracy: 0.6595 - val_loss: 0.9016 - val_accuracy: 0.5575\n",
      "Epoch 7/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7069 - accuracy: 0.6638 - val_loss: 0.8828 - val_accuracy: 0.5517\n",
      "Epoch 8/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.6796 - val_loss: 0.8932 - val_accuracy: 0.5517\n",
      "Epoch 9/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.6868 - val_loss: 0.9058 - val_accuracy: 0.5460\n",
      "Epoch 10/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.6911 - val_loss: 0.8952 - val_accuracy: 0.5747\n",
      "Epoch 11/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.6968 - val_loss: 0.9102 - val_accuracy: 0.5632\n",
      "Epoch 12/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6511 - accuracy: 0.6911 - val_loss: 0.9137 - val_accuracy: 0.5747\n",
      "Epoch 13/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6421 - accuracy: 0.7083 - val_loss: 0.9036 - val_accuracy: 0.5747\n",
      "Epoch 14/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6321 - accuracy: 0.7083 - val_loss: 0.9095 - val_accuracy: 0.5920\n",
      "Epoch 15/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.7112 - val_loss: 0.9024 - val_accuracy: 0.5690\n",
      "Epoch 16/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.7112 - val_loss: 0.9079 - val_accuracy: 0.5747\n",
      "Epoch 17/55\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6108 - accuracy: 0.7241 - val_loss: 0.8972 - val_accuracy: 0.5690\n",
      "Epoch 18/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.7241 - val_loss: 0.9016 - val_accuracy: 0.5690\n",
      "Epoch 19/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5963 - accuracy: 0.7342 - val_loss: 0.8991 - val_accuracy: 0.5747\n",
      "Epoch 20/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5875 - accuracy: 0.7342 - val_loss: 0.9023 - val_accuracy: 0.5632\n",
      "Epoch 21/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7385 - val_loss: 0.9316 - val_accuracy: 0.5862\n",
      "Epoch 22/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.7428 - val_loss: 0.8898 - val_accuracy: 0.5632\n",
      "Epoch 23/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5725 - accuracy: 0.7486 - val_loss: 0.9028 - val_accuracy: 0.5690\n",
      "Epoch 24/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7486 - val_loss: 0.9282 - val_accuracy: 0.5690\n",
      "Epoch 25/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5546 - accuracy: 0.7572 - val_loss: 0.9186 - val_accuracy: 0.5632\n",
      "Epoch 26/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7644 - val_loss: 0.9425 - val_accuracy: 0.5862\n",
      "Epoch 27/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5408 - accuracy: 0.7629 - val_loss: 0.8988 - val_accuracy: 0.5517\n",
      "Epoch 28/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7701 - val_loss: 0.9501 - val_accuracy: 0.5805\n",
      "Epoch 29/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7644 - val_loss: 0.8992 - val_accuracy: 0.5690\n",
      "Epoch 30/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7773 - val_loss: 0.9291 - val_accuracy: 0.5517\n",
      "Epoch 31/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5253 - accuracy: 0.7716 - val_loss: 0.9584 - val_accuracy: 0.5920\n",
      "Epoch 32/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7787 - val_loss: 0.9338 - val_accuracy: 0.5690\n",
      "Epoch 33/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7730 - val_loss: 0.9414 - val_accuracy: 0.5632\n",
      "Epoch 34/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5150 - accuracy: 0.7701 - val_loss: 0.9077 - val_accuracy: 0.5575\n",
      "Epoch 35/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7917 - val_loss: 0.9634 - val_accuracy: 0.5862\n",
      "Epoch 36/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7830 - val_loss: 0.9075 - val_accuracy: 0.5747\n",
      "Epoch 37/55\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4849 - accuracy: 0.7974 - val_loss: 0.9337 - val_accuracy: 0.5747\n",
      "Epoch 38/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7960 - val_loss: 0.9484 - val_accuracy: 0.5862\n",
      "Epoch 39/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.8060 - val_loss: 0.9262 - val_accuracy: 0.5747\n",
      "Epoch 40/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.8003 - val_loss: 1.0038 - val_accuracy: 0.6034\n",
      "Epoch 41/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.8175 - val_loss: 0.9651 - val_accuracy: 0.6034\n",
      "Epoch 42/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.8118 - val_loss: 0.9519 - val_accuracy: 0.5862\n",
      "Epoch 43/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.8060 - val_loss: 0.9513 - val_accuracy: 0.6034\n",
      "Epoch 44/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8161 - val_loss: 0.9477 - val_accuracy: 0.5920\n",
      "Epoch 45/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8204 - val_loss: 0.9502 - val_accuracy: 0.5977\n",
      "Epoch 46/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.8218 - val_loss: 0.9823 - val_accuracy: 0.5977\n",
      "Epoch 47/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.8319 - val_loss: 0.9813 - val_accuracy: 0.6034\n",
      "Epoch 48/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8319 - val_loss: 1.0404 - val_accuracy: 0.5977\n",
      "Epoch 49/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8434 - val_loss: 1.0361 - val_accuracy: 0.6264\n",
      "Epoch 50/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8333 - val_loss: 0.9588 - val_accuracy: 0.5977\n",
      "Epoch 51/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8405 - val_loss: 1.0226 - val_accuracy: 0.6034\n",
      "Epoch 52/55\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8463 - val_loss: 0.9964 - val_accuracy: 0.6092\n",
      "Epoch 53/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8506 - val_loss: 1.0371 - val_accuracy: 0.5862\n",
      "Epoch 54/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8477 - val_loss: 1.0317 - val_accuracy: 0.5920\n",
      "Epoch 55/55\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8635 - val_loss: 0.9958 - val_accuracy: 0.6034\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Accuracy on the filtered dataset: 0.6468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"WineQT.csv\")\n",
    "\n",
    "# Step 2: Drop the 'Id' column (not needed)\n",
    "df.drop(columns=[\"Id\"], inplace=True)\n",
    "\n",
    "# Step 3: Filter the dataset to include only quality levels 5, 6, and 7\n",
    "df_filtered = df[df['quality'].isin([5, 6, 7])]\n",
    "\n",
    "# Step 4: Separate features (X) and target (y) for the filtered dataset\n",
    "X_filtered = df_filtered.drop(columns=[\"quality\"])  # Features\n",
    "y_filtered = df_filtered[\"quality\"]  # Target variable (discrete classes)\n",
    "\n",
    "# Step 5: Map target labels to a range of [0, num_classes - 1]\n",
    "unique_classes = y_filtered.unique()\n",
    "num_classes = len(unique_classes)\n",
    "label_mapping = {label: idx for idx, label in enumerate(sorted(unique_classes))}\n",
    "y_mapped = y_filtered.map(label_mapping)\n",
    "\n",
    "# Step 6: Perform Z-score normalization (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_filtered)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_filtered.columns)\n",
    "\n",
    "# Step 7: Split the filtered data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y_mapped, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Define and train the base model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
    "    Dense(32, activation='relu'),  # Hidden layer\n",
    "    Dense(16, activation='relu'),  # Hidden layer\n",
    "    Dense(num_classes, activation='softmax')  # Output layer (num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=55, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Step 9: Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy on the filtered dataset: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8e9f72-bd5b-41cf-a29c-188de0c77e25",
   "metadata": {},
   "source": [
    "#### base model:\n",
    "Neural Network Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         0\n",
    "           1       0.00      0.00      0.00         6\n",
    "           2       0.69      0.74      0.71        96\n",
    "           3       0.59      0.52      0.55        99\n",
    "           4       0.44      0.62      0.52        26\n",
    "           5       0.00      0.00      0.00         2\n",
    "\n",
    "    accuracy                           0.60       229"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f69ffd-b8e1-4b14-9056-57a66938d0d8",
   "metadata": {},
   "source": [
    "## Modifying the Dataset to Improve Model Performance\n",
    "To improve the performance of our neural network model, we modified the dataset by removing wine samples with quality scores of 3, 4, and 8. This was not done because these values were noise but because they formed small subsets that consistently led to poor predictive performance in earlier tests. Our goal was to alter the dataset structure in a way that improves classification accuracy overall.\n",
    "\n",
    "### Reasoning Behind the Modification\n",
    "\n",
    "The dataset originally contained a wide range of quality labels, but the distribution was uneven. Some quality categories had very few samples, making them harder for the model to learn effectively. When categories have very low representation, the model tends to either overfit to these rare cases or misclassify them due to insufficient training examples. Instead of focusing on these challenging outliers, we refined the model by keeping only the dominant categories: quality 5, 6, and 7.\n",
    "\n",
    "This change created a dataset that allowed the neural network to better learn the relationships between the wine’s chemical properties and its perceived quality. By limiting the model’s focus to the most frequently occurring quality labels, we enabled it to generalize better and make more consistent predictions.\n",
    "\n",
    "### Results After Modification\n",
    "\n",
    "The results show a clear improvement in accuracy. The base model, trained on all quality levels, struggled due to the difficulty of predicting rare quality labels correctly. After filtering the dataset, the model was able to achieve more stable and reliable predictions, leading to an increase of about **4.68% in accuracy**.\n",
    "\n",
    "- **Base Model Accuracy:** 60%  \n",
    "- **Modified Model Accuracy:** 64.68%  \n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This experiment demonstrates that modifying a dataset—by removing categories that consistently lead to poor performance—can significantly enhance a model’s effectiveness in certain cases. Rather than simply tuning hyperparameters, adjusting the data itself can sometimes be the most effective way to improve results.\n",
    "\n",
    "However, it’s important to note that this approach does not necessarily create the best overall model. The removed quality categories (3, 4, and 8) are still essential for a fully representative classifier. If this were a real-world scenario, a better approach might be to use techniques such as data augmentation, resampling, or class-weighted loss to handle rare categories rather than removing them entirely.\n",
    "\n",
    "In this specific case, filtering the dataset led to improved performance by making the classification task easier, but the trade-off is that our model is now unable to predict certain quality levels at all. This highlights the balance between optimizing for accuracy and maintaining a model’s ability to generalize across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad2fae-e89c-4abc-a5e2-61d5834036d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
