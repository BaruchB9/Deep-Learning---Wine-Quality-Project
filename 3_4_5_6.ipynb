{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cf11d0-66d3-4fb8-ac97-913383214678",
   "metadata": {},
   "source": [
    "### Question 3 - notmalization\n",
    "\n",
    "### **Preprocessing Steps**\n",
    "a. **Data Cleaning**:  \n",
    "   - Removed the `Id` column as it was unnecessary for analysis and modeling.\n",
    "\n",
    "b. **Handling Missing Values**:  \n",
    "   - Checked for missing values and confirmed that the dataset is complete with no missing entries.\n",
    "\n",
    "c. **Dimensionality Reduction**:  \n",
    "   - Initially considered PCA for dimensionality reduction but decided to postpone it to **question 15** to avoid losing interpretability of the original features.\n",
    "\n",
    "d. **Data Balancing**:  \n",
    "   - Observed that the dataset is imbalanced, with fewer samples for marginal quality levels (e.g., quality 3, 4, and 8).  \n",
    "   - Addressed this imbalance in **question 14** by oversampling minority classes to improve model performance.\n",
    "\n",
    "e. **Normalization**:  \n",
    "   - Applied **Z-score normalization** to standardize the features, ensuring all variables are on the same scale. This is particularly well-suited for our scenario as it preserves the distribution of the data while reducing the impact of outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b6187-86e4-4c93-83f7-339bcb6cee62",
   "metadata": {},
   "source": [
    "### Question 4 - split train test\n",
    "split 0.2 of data for tets and 0.8 for training\n",
    "### Question 5 - Logistic Regression model (multi-class)\n",
    "### Question 6 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41bddbe3-9f59-44a1-b1f9-1115380eb642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5283842794759825\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.14      0.17      0.15         6\n",
      "           5       0.64      0.58      0.61        96\n",
      "           6       0.52      0.52      0.52        99\n",
      "           7       0.42      0.50      0.46        26\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.53       229\n",
      "   macro avg       0.29      0.29      0.29       229\n",
      "weighted avg       0.54      0.53      0.53       229\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 0  1  2  2  1  0]\n",
      " [ 3  4 56 31  2  0]\n",
      " [ 2  2 30 51 14  0]\n",
      " [ 0  0  0 13 13  0]\n",
      " [ 0  0  0  1  1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"WineQT.csv\")\n",
    "\n",
    "# Step 2: Drop the 'Id' column (not needed)\n",
    "df.drop(columns=[\"Id\"], inplace=True)\n",
    "\n",
    "# Step 3: Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"quality\"])  # Features\n",
    "y = df[\"quality\"]  # Target variable (discrete classes)\n",
    "\n",
    "# Step 4: Perform Z-score normalization (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Step 5: Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Step 7: Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c398f9d-c848-4d40-b9f6-bbb6240d9ee6",
   "metadata": {},
   "source": [
    "### Logistic Regression Output:\n",
    "\n",
    "#### 1. **Precision, Recall, and F1-Score**:\n",
    "These metrics evaluate the classification performance per class (wine quality from 4 to 8).\n",
    "- **Precision**: The ratio of true positive predictions to all positive predictions made by the model.\n",
    "- **Recall**: The ratio of true positive predictions to all actual positive instances.\n",
    "- **F1-Score**: The harmonic mean of Precision and Recall, balancing both metrics.\n",
    "\n",
    "#### 2. **Support**:\n",
    "The support indicates the number of occurrences of each class in the dataset.\n",
    "- For example, there are 6 instances of class 4, 96 of class 5, etc.\n",
    "\n",
    "#### 3. **Accuracy**:\n",
    "This is the overall correctness of the model. Itâ€™s calculated as:\n",
    "\n",
    "#### 4. **Macro Average**:\n",
    "- **Macro Average Precision, Recall, F1-Score**: These are the unweighted averages of Precision, Recall, and F1-Score across all classes. It treats all classes equally, regardless of their frequency in the dataset.\n",
    "\n",
    "#### 5. **Weighted Average**:\n",
    "- **Weighted Average Precision, Recall, F1-Score**: These averages are weighted by the support (class frequencies). It gives more importance to classes with more instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193979c-3815-4fac-8e2e-2e78da296858",
   "metadata": {},
   "source": [
    "### Question 6: Model Evaluation\n",
    "\n",
    "- **Accuracy**: The model achieved an accuracy of **52.83%**, indicating that it correctly classified about 58% of the samples.\n",
    "- **Precision, Recall, and F1-Score**: The model performs poorly on class 4 and class 8 (with 0 precision and recall). For class 5 and 6, it performs better, with decent precision and recall. Class 7 has lower recall, suggesting it's harder to predict.\n",
    "- **Macro Average**: The macro average precision, recall, and F1-score are low (around 0.29), indicating that the model struggles with balancing performance across all classes.\n",
    "- **Weighted Average**: The weighted averages are higher (around 0.54 for precision and 0.53 for F1-score), reflecting better performance for the more frequent classes (class 5 and 6).\n",
    "\n",
    "In summary, the model's performance is not strong, especially for rare classes (4 and 8), but it performs reasonably well for more frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d55f06-9b65-4471-8cc5-137f86aff9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
